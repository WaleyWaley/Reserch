{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed0f4c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "--- 步骤 0: 设备验证 ---\n",
      "✅ PyTorch 检测到 CUDA GPU 可用。\n",
      "  - GPU 型号: NVIDIA GeForce RTX 3070 Ti\n",
      "✅ Keras 张量默认被创建在: cuda:0\n",
      "✅ Keras 与 PyTorch 设备匹配。\n",
      "结论：模型将运行在 'CUDA' 设备上。\n",
      "================================================================================\n",
      "\n",
      "--- 步骤 1: 加载与预处理数据 ---\n",
      "成功加载数据集，总行数: 20302\n",
      "\n",
      "Data loaded successfully!\n",
      "Training data shape:   (16241, 22)\n",
      "Validation data shape: (2030, 22)\n",
      "Testing data shape:    (2031, 22)\n",
      "\n",
      "Identified 13 WiFi features and 6 IMU features.\n",
      "数据已在DataFrame上完成标准化。\n",
      "\n",
      "--- 步骤 2: 创建滑动窗口数据 ---\n",
      "滑动窗口数据创建完毕！\n",
      "  - X_train shape: (16209, 30, 19)\n",
      "  - y_train shape: (16209, 6)\n",
      "\n",
      "--- 步骤 3: 构建与训练 Keras TKAN 模型 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ TKAN_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TKAN</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,166</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Prediction_Head (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m19\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ TKAN_Layer (\u001b[38;5;33mTKAN\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m9,166\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Prediction_Head (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m198\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,364</span> (36.58 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,364\u001b[0m (36.58 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,174</span> (35.84 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,174\u001b[0m (35.84 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">190</span> (760.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m190\u001b[0m (760.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 开始模型训练 (model.fit) ---\n",
      "Epoch 1/50\n",
      "254/254 - 58s - 228ms/step - loss: 0.2655 - mse: 0.5626 - val_loss: 0.0684 - val_mse: 0.1371\n",
      "Epoch 2/50\n",
      "254/254 - 59s - 232ms/step - loss: 0.0412 - mse: 0.0825 - val_loss: 0.0382 - val_mse: 0.0764\n",
      "Epoch 3/50\n",
      "254/254 - 59s - 232ms/step - loss: 0.0284 - mse: 0.0568 - val_loss: 0.0343 - val_mse: 0.0686\n",
      "Epoch 4/50\n",
      "254/254 - 60s - 235ms/step - loss: 0.0213 - mse: 0.0426 - val_loss: 0.0318 - val_mse: 0.0635\n",
      "Epoch 5/50\n",
      "254/254 - 61s - 240ms/step - loss: 0.0154 - mse: 0.0308 - val_loss: 0.0266 - val_mse: 0.0533\n",
      "Epoch 6/50\n",
      "254/254 - 61s - 240ms/step - loss: 0.0109 - mse: 0.0218 - val_loss: 0.0177 - val_mse: 0.0355\n",
      "Epoch 7/50\n",
      "254/254 - 62s - 243ms/step - loss: 0.0078 - mse: 0.0156 - val_loss: 0.0161 - val_mse: 0.0321\n",
      "Epoch 8/50\n",
      "254/254 - 62s - 243ms/step - loss: 0.0057 - mse: 0.0115 - val_loss: 0.0138 - val_mse: 0.0275\n",
      "Epoch 9/50\n",
      "254/254 - 62s - 245ms/step - loss: 0.0044 - mse: 0.0088 - val_loss: 0.0121 - val_mse: 0.0241\n",
      "Epoch 10/50\n",
      "254/254 - 63s - 247ms/step - loss: 0.0035 - mse: 0.0070 - val_loss: 0.0119 - val_mse: 0.0238\n",
      "Epoch 11/50\n",
      "254/254 - 64s - 251ms/step - loss: 0.0029 - mse: 0.0058 - val_loss: 0.0112 - val_mse: 0.0224\n",
      "Epoch 12/50\n",
      "254/254 - 71s - 280ms/step - loss: 0.0025 - mse: 0.0049 - val_loss: 0.0118 - val_mse: 0.0237\n",
      "Epoch 13/50\n",
      "254/254 - 72s - 285ms/step - loss: 0.0021 - mse: 0.0042 - val_loss: 0.0119 - val_mse: 0.0237\n",
      "Epoch 14/50\n",
      "254/254 - 79s - 313ms/step - loss: 0.0019 - mse: 0.0037 - val_loss: 0.0107 - val_mse: 0.0214\n",
      "Epoch 15/50\n",
      "254/254 - 78s - 307ms/step - loss: 0.0017 - mse: 0.0033 - val_loss: 0.0109 - val_mse: 0.0218\n",
      "Epoch 16/50\n",
      "254/254 - 72s - 283ms/step - loss: 0.0015 - mse: 0.0030 - val_loss: 0.0113 - val_mse: 0.0226\n",
      "Epoch 17/50\n",
      "254/254 - 77s - 302ms/step - loss: 0.0013 - mse: 0.0027 - val_loss: 0.0107 - val_mse: 0.0213\n",
      "Epoch 18/50\n",
      "254/254 - 76s - 298ms/step - loss: 0.0012 - mse: 0.0024 - val_loss: 0.0101 - val_mse: 0.0202\n",
      "Epoch 19/50\n",
      "254/254 - 75s - 296ms/step - loss: 0.0011 - mse: 0.0022 - val_loss: 0.0109 - val_mse: 0.0218\n",
      "Epoch 20/50\n",
      "254/254 - 81s - 321ms/step - loss: 0.0010 - mse: 0.0021 - val_loss: 0.0106 - val_mse: 0.0213\n",
      "Epoch 21/50\n",
      "254/254 - 80s - 317ms/step - loss: 9.5154e-04 - mse: 0.0019 - val_loss: 0.0099 - val_mse: 0.0197\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 212\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;66;03m# 【注释】这是真正的“训练”步骤，模型的权重会在这里被更新。\u001b[39;00m\n\u001b[32m    211\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- 开始模型训练 (model.fit) ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\n\u001b[32m    220\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m--- 模型训练结束 ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    224\u001b[39m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[32m    225\u001b[39m \u001b[38;5;66;03m#  第四部分：评估\u001b[39;00m\n\u001b[32m    226\u001b[39m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[32m    227\u001b[39m \u001b[38;5;66;03m# 【注释】下面的步骤是在训练结束后，使用已经训练好的最佳模型在“测试集”上进行评估。\u001b[39;00m\n\u001b[32m    228\u001b[39m \u001b[38;5;66;03m# 【注释】模型的权重在此阶段是冻结的，不会再改变。\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\backend\\torch\\trainer.py:269\u001b[39m, in \u001b[36mTorchTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, data \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    266\u001b[39m     \u001b[38;5;66;03m# Callbacks\u001b[39;00m\n\u001b[32m    267\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m     \u001b[38;5;66;03m# Callbacks\u001b[39;00m\n\u001b[32m    272\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\backend\\torch\\trainer.py:124\u001b[39m, in \u001b[36mTorchTrainer.make_train_function.<locals>.one_step_on_data\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[32m    123\u001b[39m data = data[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\backend\\torch\\trainer.py:45\u001b[39m, in \u001b[36mTorchTrainer.train_step\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Compute predictions\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_has_training_arg:\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     y_pred = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     47\u001b[39m     y_pred = \u001b[38;5;28mself\u001b[39m(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\layers\\layer.py:941\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    939\u001b[39m         outputs = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*args, **kwargs)\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m941\u001b[39m     outputs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[32m    943\u001b[39m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[32m    945\u001b[39m distribution = distribution_lib.distribution()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\backend\\torch\\layer.py:41\u001b[39m, in \u001b[36mTorchLayer.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOperation\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\ops\\operation.py:59\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m                 call_fn = \u001b[38;5;28mself\u001b[39m.call\n\u001b[32m     55\u001b[39m     call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     56\u001b[39m         call_fn,\n\u001b[32m     57\u001b[39m         object_name=(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.call()\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     58\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    159\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\models\\functional.py:183\u001b[39m, in \u001b[36mFunctional.call\u001b[39m\u001b[34m(self, inputs, training, mask, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    182\u001b[39m             backend.set_keras_mask(x, mask)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_through_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m unpack_singleton(outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\ops\\function.py:206\u001b[39m, in \u001b[36mFunction._run_through_graph\u001b[39m\u001b[34m(self, inputs, operation_fn, call_fn)\u001b[39m\n\u001b[32m    204\u001b[39m     operation = \u001b[38;5;28mself\u001b[39m._get_operation_for_node(node)\n\u001b[32m    205\u001b[39m     op = operation_fn(operation)\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     outputs = \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node.outputs, tree.flatten(outputs)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\models\\functional.py:644\u001b[39m, in \u001b[36moperation_fn.<locals>.call\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    639\u001b[39m         name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(operation, \u001b[33m\"\u001b[39m\u001b[33m_call_context_args\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m    640\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    641\u001b[39m     ):\n\u001b[32m    642\u001b[39m         kwargs[name] = value\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\layers\\layer.py:941\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    939\u001b[39m         outputs = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*args, **kwargs)\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m941\u001b[39m     outputs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[32m    943\u001b[39m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[32m    945\u001b[39m distribution = distribution_lib.distribution()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\backend\\torch\\layer.py:41\u001b[39m, in \u001b[36mTorchLayer.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOperation\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\ops\\operation.py:59\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m                 call_fn = \u001b[38;5;28mself\u001b[39m.call\n\u001b[32m     55\u001b[39m     call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     56\u001b[39m         call_fn,\n\u001b[32m     57\u001b[39m         object_name=(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.call()\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     58\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    159\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\科研\\科研\\tkan\\tkan.py:469\u001b[39m, in \u001b[36mTKAN.call\u001b[39m\u001b[34m(self, sequences, initial_state, mask, training)\u001b[39m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, sequences, initial_state=\u001b[38;5;28;01mNone\u001b[39;00m, mask=\u001b[38;5;28;01mNone\u001b[39;00m, training=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m        \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_state\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:425\u001b[39m, in \u001b[36mRNN.call\u001b[39m\u001b[34m(self, sequences, initial_state, mask, training)\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;66;03m# Prepopulate the dropout state so that the inner_loop is stateless\u001b[39;00m\n\u001b[32m    420\u001b[39m \u001b[38;5;66;03m# this is particularly important for JAX backend.\u001b[39;00m\n\u001b[32m    421\u001b[39m \u001b[38;5;28mself\u001b[39m._maybe_config_dropout_masks(\n\u001b[32m    422\u001b[39m     \u001b[38;5;28mself\u001b[39m.cell, sequences[:, \u001b[32m0\u001b[39m, :], initial_state\n\u001b[32m    423\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m last_output, outputs, states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minner_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m    \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m=\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    431\u001b[39m last_output = ops.cast(last_output, \u001b[38;5;28mself\u001b[39m.compute_dtype)\n\u001b[32m    432\u001b[39m outputs = ops.cast(outputs, \u001b[38;5;28mself\u001b[39m.compute_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\科研\\科研\\tkan\\tkan.py:464\u001b[39m, in \u001b[36mTKAN.inner_loop\u001b[39m\u001b[34m(self, sequences, initial_state, mask, training)\u001b[39m\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mask, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m    463\u001b[39m     mask = mask[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minner_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m    \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:350\u001b[39m, in \u001b[36mRNN.inner_loop\u001b[39m\u001b[34m(self, sequences, initial_state, mask, training)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tree.is_nested(initial_state):\n\u001b[32m    348\u001b[39m     initial_state = [initial_state]\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgo_backwards\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgo_backwards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43munroll\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43munroll\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mzero_output_for_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mzero_output_for_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_all_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\backend\\torch\\rnn.py:353\u001b[39m, in \u001b[36mrnn\u001b[39m\u001b[34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask, return_all_outputs)\u001b[39m\n\u001b[32m    351\u001b[39m new_states = states\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m time < time_steps_t \u001b[38;5;129;01mand\u001b[39;00m it < max_iterations:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     final_outputs = \u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_ta_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mnew_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m     time, output_ta_t = final_outputs[:\u001b[32m2\u001b[39m]\n\u001b[32m    355\u001b[39m     new_states = final_outputs[\u001b[32m2\u001b[39m:]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\backend\\torch\\rnn.py:334\u001b[39m, in \u001b[36mrnn.<locals>._step\u001b[39m\u001b[34m(time, output_ta_t, *states)\u001b[39m\n\u001b[32m    332\u001b[39m current_input = \u001b[38;5;28mtuple\u001b[39m(ta[time] \u001b[38;5;28;01mfor\u001b[39;00m ta \u001b[38;5;129;01min\u001b[39;00m input_ta)\n\u001b[32m    333\u001b[39m current_input = tree.pack_sequence_as(inputs, current_input)\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m output, new_states = \u001b[43mstep_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcurrent_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    337\u001b[39m flat_new_state = tree.flatten(new_states)\n\u001b[32m    339\u001b[39m flat_output = tree.flatten(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:342\u001b[39m, in \u001b[36mRNN.inner_loop.<locals>.step\u001b[39m\u001b[34m(inputs, states)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.backend() == \u001b[33m\"\u001b[39m\u001b[33mtorch\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stateful:\n\u001b[32m    341\u001b[39m     states = tree.map_structure(ops.copy, states)\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m output, new_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcell_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tree.is_nested(new_states):\n\u001b[32m    344\u001b[39m     new_states = [new_states]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\layers\\layer.py:941\u001b[39m, in \u001b[36mLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    939\u001b[39m         outputs = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(*args, **kwargs)\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m941\u001b[39m     outputs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[32m    943\u001b[39m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[32m    945\u001b[39m distribution = distribution_lib.distribution()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\backend\\torch\\layer.py:41\u001b[39m, in \u001b[36mTorchLayer.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mOperation\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\ops\\operation.py:59\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     54\u001b[39m                 call_fn = \u001b[38;5;28mself\u001b[39m.call\n\u001b[32m     55\u001b[39m     call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     56\u001b[39m         call_fn,\n\u001b[32m     57\u001b[39m         object_name=(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.call()\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     58\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001b[39m, in \u001b[36minject_argument_info_in_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    154\u001b[39m bound_signature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33m_keras_call_info_injected\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    159\u001b[39m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\科研\\科研\\tkan\\tkan.py:258\u001b[39m, in \u001b[36mTKANCell.call\u001b[39m\u001b[34m(self, inputs, states, training)\u001b[39m\n\u001b[32m    256\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_tensorflow(inputs, states, training)\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_generic\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\科研\\科研\\tkan\\tkan.py:331\u001b[39m, in \u001b[36mTKANCell._call_generic\u001b[39m\u001b[34m(self, inputs, states, training)\u001b[39m\n\u001b[32m    328\u001b[39m         h_tm1 *= rec_dp_mask\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.use_bias:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     gates = \u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_tm1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrecurrent_kernel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    333\u001b[39m     gates = ops.matmul(inputs, \u001b[38;5;28mself\u001b[39m.kernel) + ops.matmul(h_tm1, \u001b[38;5;28mself\u001b[39m.recurrent_kernel)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Desktop\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\keras\\src\\backend\\torch\\core.py:129\u001b[39m, in \u001b[36mVariable.__torch_function__\u001b[39m\u001b[34m(cls, func, types, args, kwargs)\u001b[39m\n\u001b[32m    124\u001b[39m     kwargs = {}\n\u001b[32m    125\u001b[39m kwargs = {\n\u001b[32m    126\u001b[39m     key: value.value \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Variable) \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[32m    127\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items()\n\u001b[32m    128\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ==============================================================================\n",
    "#  环境设置与依赖检查\n",
    "# ==============================================================================\n",
    "\n",
    "# 设置 Keras 后端为 PyTorch，确保在导入 Keras 之前执行\n",
    "os.environ['KERAS_BACKEND'] = 'torch'\n",
    "\n",
    "try:\n",
    "    import keras\n",
    "    import torch # 导入 torch 以进行设备检查\n",
    "    from packaging.version import parse as parse_version\n",
    "    \n",
    "    # 【核心】增加 Keras 版本检查\n",
    "    if parse_version(keras.__version__) < parse_version(\"3.0.0\"):\n",
    "        print(\"=\"*80)\n",
    "        print(\"错误：检测到过时的 Keras 版本。\")\n",
    "        print(f\"您当前安装的 Keras 版本是 {keras.__version__}，但 TKAN 库需要 Keras 3 或更高版本。\")\n",
    "        print(\"Keras 3 引入了 'keras.ops' 模块，这是 TKAN 正常运行所必需的。\")\n",
    "        print(\"\\n请在您的 conda 环境中运行以下命令来升级：\")\n",
    "        print(\"pip install --upgrade keras tensorflow\")\n",
    "        print(\"=\"*80)\n",
    "        exit() # 终止程序\n",
    "\n",
    "    # 【核心修正】修正 TKAN 的导入路径\n",
    "    from tkan import TKAN \n",
    "\n",
    "except ImportError as e:\n",
    "    # 捕获其他导入错误，并提供清晰的指导\n",
    "    if \"No module named 'tensorflow'\" in str(e):\n",
    "        print(\"=\"*80)\n",
    "        print(\"错误：缺少 TensorFlow 依赖。\")\n",
    "        print(\"Keras 3 框架，即使在 PyTorch 后端模式下，也需要安装 TensorFlow 才能正常导入。\")\n",
    "        print(\"\\n请在您的 conda 环境中运行以下命令来安装：\")\n",
    "        print(\"pip install tensorflow\")\n",
    "        print(\"=\"*80)\n",
    "        exit() # 终止程序\n",
    "    elif \"No module named 'torch'\" in str(e):\n",
    "        print(\"=\"*80)\n",
    "        print(\"错误：缺少 PyTorch 依赖。\")\n",
    "        print(\"您已将 Keras 后端设置为 'torch'，但当前环境中未找到 PyTorch。\")\n",
    "        print(\"\\n请在您的 conda 环境中运行以下命令来安装：\")\n",
    "        print(\"pip install torch torchvision torchaudio\")\n",
    "        print(\"=\"*80)\n",
    "        exit()\n",
    "    else:\n",
    "        # 如果是其他导入错误，则正常抛出\n",
    "        raise e\n",
    "\n",
    "# ==============================================================================\n",
    "#  【核心新增】设备验证模块\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"--- 步骤 0: 设备验证 ---\")\n",
    "try:\n",
    "    if torch.cuda.is_available():\n",
    "        DEVICE_NAME = \"cuda\"\n",
    "        print(\"✅ PyTorch 检测到 CUDA GPU 可用。\")\n",
    "        print(f\"  - GPU 型号: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        DEVICE_NAME = \"cpu\"\n",
    "        print(\"❌ 警告：PyTorch 未能找到可用的 CUDA GPU。\")\n",
    "\n",
    "    # Keras 3 (torch backend) 会遵循 torch 的设备\n",
    "    # 我们可以通过创建一个张量来验证 Keras 当前的默认设备\n",
    "    test_tensor = keras.ops.convert_to_tensor([1.0])\n",
    "    print(f\"✅ Keras 张量默认被创建在: {test_tensor.device}\")\n",
    "    \n",
    "    if DEVICE_NAME == \"cpu\" and \"cpu\" not in str(test_tensor.device):\n",
    "        print(\"⚠️ 注意：PyTorch 未找到 GPU，但 Keras 似乎指向了非 CPU 设备。可能存在配置冲突。\")\n",
    "    elif DEVICE_NAME == \"cuda\" and \"cuda\" not in str(test_tensor.device):\n",
    "        print(\"❌ 错误：PyTorch 找到了 GPU，但 Keras 未能使用它！训练将在 CPU 上进行。\")\n",
    "    else:\n",
    "        print(\"✅ Keras 与 PyTorch 设备匹配。\")\n",
    "\n",
    "except Exception as e:\n",
    "    DEVICE_NAME = \"cpu\"\n",
    "    print(f\"❌ 设备验证失败: {e}。将默认使用 CPU。\")\n",
    "print(f\"结论：模型将运行在 '{DEVICE_NAME.upper()}' 设备上。\")\n",
    "print(\"=\"*80)\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "#  第一部分：数据加载与预处理 (来自您的代码)\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 步骤 1: 加载与预处理数据 ---\")\n",
    "dictory = \"../Datasets/\"\n",
    "filename = \"0.275_Speed_OB.csv\"\n",
    "data = pd.read_csv(dictory+filename)\n",
    "# data = pd.read_csv(r'../Datasets/0.15_Speed_withouOB.csv')\n",
    "print(f\"成功加载数据集，总行数: {len(data)}\")\n",
    "\n",
    "# 定义分割比例\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "data_size = len(data)\n",
    "train_end_idx = int(train_ratio * data_size)\n",
    "val_end_idx = train_end_idx + int(val_ratio * data_size)\n",
    "\n",
    "# 使用 .iloc 分割 DataFrame\n",
    "train_data = data.iloc[:train_end_idx]\n",
    "val_data = data.iloc[train_end_idx:val_end_idx]\n",
    "test_data = data.iloc[val_end_idx:]\n",
    "\n",
    "# train_data = pd.read_csv(\n",
    "#     r'../Datasets/zoulang/train.csv')\n",
    "# val_data = pd.read_csv(\n",
    "#     r'../Datasets/zoulang/validation.csv')\n",
    "# test_data = pd.read_csv(\n",
    "#     r'../Datasets/zoulang/test.csv')\n",
    "\n",
    "print(\"\\nData loaded successfully!\")\n",
    "print(f\"Training data shape:   {train_data.shape}\")\n",
    "print(f\"Validation data shape: {val_data.shape}\")\n",
    "print(f\"Testing data shape:    {test_data.shape}\")\n",
    "\n",
    "column_names = train_data.drop(['timestamp','x_coord', 'y_coord'], axis=1).columns.tolist()\n",
    "wifi_features = [col for col in column_names if any(sensor in col for sensor in [\"rot\", \"RSSI\"])]\n",
    "# wifi_features = [col for col in column_names if any(sensor in col for sensor in [\"RSSI\",\"distance\"])] \n",
    "# imu_features = [col for col in column_names if any(sensor in col for sensor in [\"accelerometer\", \"gyroscope\"])]\n",
    "imu_features = [col for col in column_names if any(sensor in col for sensor in [\"accelerometer\", \"gyroscope\",\"magnetometer\"])] \n",
    "print(f\"\\nIdentified {len(wifi_features)} WiFi features and {len(imu_features)} IMU features.\")\n",
    "coord_cols = ['x_coord', 'y_coord']\n",
    "# 在DataFrame上进行标准化\n",
    "scaler_wifi = StandardScaler().fit(train_data[wifi_features])\n",
    "scaler_imu = StandardScaler().fit(train_data[imu_features])\n",
    "coords=train_data[['x_coord','y_coord']]\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(coords)\n",
    "\n",
    "train_df_scaled = train_data.copy()\n",
    "val_df_scaled = val_data.copy()\n",
    "test_df_scaled = test_data.copy()\n",
    "\n",
    "for df in [train_df_scaled, val_df_scaled, test_df_scaled]:\n",
    "    df[wifi_features] = scaler_wifi.transform(df[wifi_features])\n",
    "    df[imu_features] = scaler_imu.transform(df[imu_features])\n",
    "    df[coord_cols] = scaler.transform(df[coord_cols])\n",
    "\n",
    "print(\"数据已在DataFrame上完成标准化。\")\n",
    "\n",
    "# ==============================================================================\n",
    "#  第二部分：数据塑形 - 创建滑动窗口\n",
    "# ==============================================================================\n",
    "def create_sliding_windows(df, feature_cols, label_cols, window_size, future_steps):\n",
    "    \"\"\"\n",
    "    将时序 DataFrame 转换为适用于 Keras RNN 模型的滑动窗口数据。\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    num_samples = len(df) - window_size - future_steps + 1\n",
    "    \n",
    "    feature_data = df[feature_cols].values\n",
    "    label_data = df[label_cols].values\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        feature_window = feature_data[i : i + window_size]\n",
    "        X.append(feature_window)\n",
    "        label_window = label_data[i + window_size : i + window_size + future_steps]\n",
    "        y.append(label_window.flatten())\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "print(\"\\n--- 步骤 2: 创建滑动窗口数据 ---\")\n",
    "windows_size = 30\n",
    "future_steps = 3\n",
    "\n",
    "all_features = wifi_features + imu_features\n",
    "label_cols = ['x_coord', 'y_coord']\n",
    "\n",
    "X_train, y_train = create_sliding_windows(train_df_scaled, all_features, label_cols, windows_size, future_steps)\n",
    "X_val, y_val = create_sliding_windows(val_df_scaled, all_features, label_cols, windows_size, future_steps)\n",
    "X_test, y_test = create_sliding_windows(test_df_scaled, all_features, label_cols, windows_size, future_steps)\n",
    "\n",
    "print(\"滑动窗口数据创建完毕！\")\n",
    "print(f\"  - X_train shape: {X_train.shape}\")\n",
    "print(f\"  - y_train shape: {y_train.shape}\")\n",
    "\n",
    "# ==============================================================================\n",
    "#  第三部分：Keras TKAN 模型训练与评估\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 步骤 3: 构建与训练 Keras TKAN 模型 ---\")\n",
    "\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "output_dim = y_train.shape[1]\n",
    "\n",
    "# 【注意】Keras with PyTorch backend 会自动将模型和数据移动到检测到的设备\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "tkan_output = TKAN(units=32, return_sequences=False, name=\"TKAN_Layer\")(inputs)\n",
    "outputs = keras.layers.Dense(output_dim, name=\"Prediction_Head\")(tkan_output)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
    "    loss=keras.losses.Huber(),\n",
    "    metrics=['mse']\n",
    ")\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# 【注释】这是真正的“训练”步骤，模型的权重会在这里被更新。\n",
    "print(\"\\n--- 开始模型训练 (model.fit) ---\")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=50,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=2\n",
    ")\n",
    "print(\"--- 模型训练结束 ---\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "#  第四部分：评估\n",
    "# ==============================================================================\n",
    "# 【注释】下面的步骤是在训练结束后，使用已经训练好的最佳模型在“测试集”上进行评估。\n",
    "# 【注释】模型的权重在此阶段是冻结的，不会再改变。\n",
    "print(\"\\n--- 步骤 4: 在测试集上评估最终模型 ---\")\n",
    "\n",
    "# 【注释】model.evaluate()：计算测试集上的损失。您会看到一个短暂的进度条。\n",
    "print(\"\\n--- 开始在测试集上评估 (model.evaluate) ---\")\n",
    "test_loss, test_mse = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# 【注释】model.predict()：生成对测试集的具体预测值，用于计算RMSE/ADE。您会看到另一个短暂的进度条。\n",
    "print(\"\\n--- 开始在测试集上预测 (model.predict) ---\")\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 【修正】修正了 y_test_seq 的 reshape 笔误\n",
    "y_test_seq = y_test.reshape(-1, future_steps, 2)\n",
    "y_pred_seq = y_pred.reshape(-1, future_steps, 2)\n",
    "\n",
    "true_coords_scaled = y_test_seq[:, -1, :]\n",
    "pred_coords_scaled = y_pred_seq[:, -1, :]\n",
    "\n",
    "true_coords = np.concatenate([\n",
    "    scaler_x.inverse_transform(true_coords_scaled[:, 0:1]),\n",
    "    scaler_y.inverse_transform(true_coords_scaled[:, 1:2])\n",
    "], axis=1)\n",
    "\n",
    "pred_coords = np.concatenate([\n",
    "    scaler_x.inverse_transform(pred_coords_scaled[:, 0:1]),\n",
    "    scaler_y.inverse_transform(pred_coords_scaled[:, 1:2])\n",
    "], axis=1)\n",
    "\n",
    "rmse = np.sqrt(np.mean((true_coords - pred_coords)**2))\n",
    "ade = np.mean(np.sqrt(np.sum((true_coords - pred_coords)**2, axis=1)))\n",
    "\n",
    "print(\"\\n--- Keras TKAN 模型评估结果 ---\")\n",
    "print(f\"Test Loss (Huber): {test_loss:.4f}\")\n",
    "print(f\"Test MSE: {test_mse:.4f} (米^2, 标准化后)\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"总均方根误差 (RMSE): {rmse:.4f} (米)\")\n",
    "print(f\"平均位移误差 (ADE/FDE): {ade:.4f} (米)\")\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "#  第五部分：保存最终预测结果\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 步骤 5: 保存预测结果到 CSV 文件 ---\")\n",
    "results_df = pd.DataFrame({\n",
    "    'True_X': true_coords[:, 0],\n",
    "    'True_Y': true_coords[:, 1],\n",
    "    'Pred_X': pred_coords[:, 0],\n",
    "    'Pred_Y': pred_coords[:, 1]\n",
    "})\n",
    "\n",
    "output_filename = 'results/tkan_zoulang.csv'\n",
    "os.makedirs('results', exist_ok=True) # 确保 results 文件夹存在\n",
    "results_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"✅ 预测结果已成功保存到: {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07370840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "--- 步骤 0: 设备验证 ---\n",
      "✅ PyTorch 检测到 CUDA GPU 可用。\n",
      "  - GPU 型号: NVIDIA GeForce RTX 3070 Ti\n",
      "✅ Keras 张量默认被创建在: cuda:0\n",
      "✅ Keras 与 PyTorch 设备匹配。\n",
      "结论：模型将运行在 'CUDA' 设备上。\n",
      "================================================================================\n",
      "成功加载数据集，总行数: 13824\n",
      "\n",
      "Data loaded successfully!\n",
      "Training data shape:   (11059, 22)\n",
      "Validation data shape: (1382, 22)\n",
      "Testing data shape:    (1383, 22)\n",
      "\n",
      "Identified 13 WiFi features and 6 IMU features.\n",
      "数据已在DataFrame上完成标准化。\n",
      "\n",
      "--- 步骤 2: 创建滑动窗口数据 ---\n",
      "滑动窗口数据创建完毕！\n",
      "  - X_train shape: (11037, 20, 19)\n",
      "  - y_train shape: (11037, 6)\n",
      "\n",
      "--- 步骤 3: 构建与训练 Keras TKAN 模型 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ TKAN_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TKAN</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,166</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Prediction_Head (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m19\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ TKAN_Layer (\u001b[38;5;33mTKAN\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m9,166\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Prediction_Head (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m198\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,364</span> (36.58 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,364\u001b[0m (36.58 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,174</span> (35.84 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,174\u001b[0m (35.84 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">190</span> (760.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m190\u001b[0m (760.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 开始模型训练 (model.fit) ---\n",
      "Epoch 1/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 274ms/step - loss: 0.3064 - mse: 0.6703 - val_loss: 0.0529 - val_mse: 0.1058\n",
      "Epoch 2/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 332ms/step - loss: 0.0557 - mse: 0.1121 - val_loss: 0.0582 - val_mse: 0.1164\n",
      "Epoch 3/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 281ms/step - loss: 0.0262 - mse: 0.0524 - val_loss: 0.0536 - val_mse: 0.1072\n",
      "Epoch 4/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 278ms/step - loss: 0.0223 - mse: 0.0446 - val_loss: 0.0506 - val_mse: 0.1011\n",
      "Epoch 5/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 295ms/step - loss: 0.0199 - mse: 0.0399 - val_loss: 0.0479 - val_mse: 0.0958\n",
      "Epoch 6/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 297ms/step - loss: 0.0182 - mse: 0.0364 - val_loss: 0.0454 - val_mse: 0.0908\n",
      "Epoch 7/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 292ms/step - loss: 0.0168 - mse: 0.0337 - val_loss: 0.0430 - val_mse: 0.0860\n",
      "Epoch 8/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 304ms/step - loss: 0.0156 - mse: 0.0313 - val_loss: 0.0406 - val_mse: 0.0812\n",
      "Epoch 9/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 301ms/step - loss: 0.0146 - mse: 0.0291 - val_loss: 0.0383 - val_mse: 0.0767\n",
      "Epoch 10/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 294ms/step - loss: 0.0136 - mse: 0.0271 - val_loss: 0.0362 - val_mse: 0.0724\n",
      "Epoch 11/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 299ms/step - loss: 0.0126 - mse: 0.0252 - val_loss: 0.0342 - val_mse: 0.0683\n",
      "Epoch 12/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 305ms/step - loss: 0.0116 - mse: 0.0233 - val_loss: 0.0323 - val_mse: 0.0645\n",
      "Epoch 13/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 311ms/step - loss: 0.0107 - mse: 0.0215 - val_loss: 0.0305 - val_mse: 0.0609\n",
      "Epoch 14/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 337ms/step - loss: 0.0099 - mse: 0.0197 - val_loss: 0.0287 - val_mse: 0.0574\n",
      "Epoch 15/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 295ms/step - loss: 0.0090 - mse: 0.0181 - val_loss: 0.0270 - val_mse: 0.0539\n",
      "Epoch 16/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 314ms/step - loss: 0.0083 - mse: 0.0166 - val_loss: 0.0254 - val_mse: 0.0507\n",
      "Epoch 17/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 289ms/step - loss: 0.0077 - mse: 0.0154 - val_loss: 0.0239 - val_mse: 0.0477\n",
      "Epoch 18/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 298ms/step - loss: 0.0072 - mse: 0.0143 - val_loss: 0.0225 - val_mse: 0.0449\n",
      "Epoch 19/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 278ms/step - loss: 0.0067 - mse: 0.0134 - val_loss: 0.0212 - val_mse: 0.0424\n",
      "Epoch 20/20\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 287ms/step - loss: 0.0063 - mse: 0.0127 - val_loss: 0.0200 - val_mse: 0.0400\n",
      "--- 模型训练结束 ---\n",
      "\n",
      "--- 步骤 4: 在测试集上评估最终模型 ---\n",
      "\n",
      "--- 开始在测试集上评估 (model.evaluate) ---\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 199ms/step - loss: 0.0277 - mse: 0.0554\n",
      "\n",
      "--- 开始在测试集上预测 (model.predict) ---\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 194ms/step\n",
      "\n",
      "--- Keras TKAN 模型评估结果 ---\n",
      "Test Loss (Huber): 0.0277\n",
      "Test MSE: 0.0554 (米^2, 标准化后)\n",
      "--------------------\n",
      "总均方根误差 (RMSE): 0.2440 (米)\n",
      "平均位移误差 (ADE/FDE): 0.3075 (米)\n",
      "---------------------------------\n",
      "\n",
      "--- 步骤 5: 保存预测结果到 CSV 文件 ---\n",
      "✅ 预测结果已成功保存到: results/tkan_UWP.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ==============================================================================\n",
    "#  环境设置与依赖检查\n",
    "# ==============================================================================\n",
    "\n",
    "# 设置 Keras 后端为 PyTorch，确保在导入 Keras 之前执行\n",
    "os.environ['KERAS_BACKEND'] = 'torch'\n",
    "\n",
    "try:\n",
    "    import keras\n",
    "    import torch # 导入 torch 以进行设备检查\n",
    "    from packaging.version import parse as parse_version\n",
    "\n",
    "    # 【核心】增加 Keras 版本检查\n",
    "    if parse_version(keras.__version__) < parse_version(\"3.0.0\"):\n",
    "        print(\"=\"*80)\n",
    "        print(\"错误：检测到过时的 Keras 版本。\")\n",
    "        print(f\"您当前安装的 Keras 版本是 {keras.__version__}，但 TKAN 库需要 Keras 3 或更高版本。\")\n",
    "        print(\"Keras 3 引入了 'keras.ops' 模块，这是 TKAN 正常运行所必需的。\")\n",
    "        print(\"\\n请在您的 conda 环境中运行以下命令来升级：\")\n",
    "        print(\"pip install --upgrade keras tensorflow\")\n",
    "        print(\"=\"*80)\n",
    "        exit() # 终止程序\n",
    "\n",
    "    # 【核心修正】修正 TKAN 的导入路径\n",
    "    from tkan import TKAN\n",
    "\n",
    "except ImportError as e:\n",
    "    # 捕获其他导入错误，并提供清晰的指导\n",
    "    if \"No module named 'tensorflow'\" in str(e):\n",
    "        print(\"=\"*80)\n",
    "        print(\"错误：缺少 TensorFlow 依赖。\")\n",
    "        print(\"Keras 3 框架，即使在 PyTorch 后端模式下，也需要安装 TensorFlow 才能正常导入。\")\n",
    "        print(\"\\n请在您的 conda 环境中运行以下命令来安装：\")\n",
    "        print(\"pip install tensorflow\")\n",
    "        print(\"=\"*80)\n",
    "        exit() # 终止程序\n",
    "    elif \"No module named 'torch'\" in str(e):\n",
    "        print(\"=\"*80)\n",
    "        print(\"错误：缺少 PyTorch 依赖。\")\n",
    "        print(\"您已将 Keras 后端设置为 'torch'，但当前环境中未找到 PyTorch。\")\n",
    "        print(\"\\n请在您的 conda 环境中运行以下命令来安装：\")\n",
    "        print(\"pip install torch torchvision torchaudio\")\n",
    "        print(\"=\"*80)\n",
    "        exit()\n",
    "    else:\n",
    "        # 如果是其他导入错误，则正常抛出\n",
    "        raise e\n",
    "\n",
    "# ==============================================================================\n",
    "#  【核心新增】设备验证模块\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"--- 步骤 0: 设备验证 ---\")\n",
    "try:\n",
    "    if torch.cuda.is_available():\n",
    "        DEVICE_NAME = \"cuda\"\n",
    "        print(\"✅ PyTorch 检测到 CUDA GPU 可用。\")\n",
    "        print(f\"  - GPU 型号: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        DEVICE_NAME = \"cpu\"\n",
    "        print(\"❌ 警告：PyTorch 未能找到可用的 CUDA GPU。\")\n",
    "\n",
    "    # Keras 3 (torch backend) 会遵循 torch 的设备\n",
    "    # 我们可以通过创建一个张量来验证 Keras 当前的默认设备\n",
    "    test_tensor = keras.ops.convert_to_tensor([1.0])\n",
    "    print(f\"✅ Keras 张量默认被创建在: {test_tensor.device}\")\n",
    "\n",
    "    if DEVICE_NAME == \"cpu\" and \"cpu\" not in str(test_tensor.device):\n",
    "        print(\"⚠️ 注意：PyTorch 未找到 GPU，但 Keras 似乎指向了非 CPU 设备。可能存在配置冲突。\")\n",
    "    elif DEVICE_NAME == \"cuda\" and \"cuda\" not in str(test_tensor.device):\n",
    "        print(\"❌ 错误：PyTorch 找到了 GPU，但 Keras 未能使用它！训练将在 CPU 上进行。\")\n",
    "    else:\n",
    "        print(\"✅ Keras 与 PyTorch 设备匹配。\")\n",
    "\n",
    "except Exception as e:\n",
    "    DEVICE_NAME = \"cpu\"\n",
    "    print(f\"❌ 设备验证失败: {e}。将默认使用 CPU。\")\n",
    "print(f\"结论：模型将运行在 '{DEVICE_NAME.upper()}' 设备上。\")\n",
    "print(\"=\"*80)\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "#  第一部分：数据加载与预处理\n",
    "# ==============================================================================\n",
    "# print(\"\\n--- 步骤 1: 加载与预处理数据 ---\")\n",
    "# train_data = pd.read_csv(\n",
    "#     r'../Datasets/zoulang/train.csv')\n",
    "# val_data = pd.read_csv(\n",
    "#     r'../Datasets/zoulang/validation.csv')\n",
    "# test_data = pd.read_csv(\n",
    "#     r'../Datasets/zoulang/test.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dictory = \"../Datasets/\"\n",
    "filename = \"0.15_Speed_withoutOB.csv\"\n",
    "data = pd.read_csv(dictory+filename)\n",
    "# data = pd.read_csv(r'../Datasets/0.45_Speed_withouOB.csv')\n",
    "print(f\"成功加载数据集，总行数: {len(data)}\")\n",
    "\n",
    "# 定义分割比例\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "data_size = len(data)\n",
    "train_end_idx = int(train_ratio * data_size)\n",
    "val_end_idx = train_end_idx + int(val_ratio * data_size)\n",
    "\n",
    "# 使用 .iloc 分割 DataFrame\n",
    "train_data = data.iloc[:train_end_idx]\n",
    "val_data = data.iloc[train_end_idx:val_end_idx]\n",
    "test_data = data.iloc[val_end_idx:]\n",
    "\n",
    "print(\"\\nData loaded successfully!\")\n",
    "print(f\"Training data shape:   {train_data.shape}\")\n",
    "print(f\"Validation data shape: {val_data.shape}\")\n",
    "print(f\"Testing data shape:    {test_data.shape}\")\n",
    "\n",
    "column_names = train_data.drop(['timestamp','x_coord', 'y_coord'], axis=1).columns.tolist()\n",
    "wifi_features = [col for col in column_names if any(sensor in col for sensor in [\"RSSI\",\"distance\",\"rot\"])]\n",
    "imu_features = [col for col in column_names if any(sensor in col for sensor in [\"accelerometer\", \"gyroscope\",\"magnetometer\"])]\n",
    "print(f\"\\nIdentified {len(wifi_features)} WiFi features and {len(imu_features)} IMU features.\")\n",
    "coord_cols = ['x_coord', 'y_coord']\n",
    "\n",
    "# --- 【核心逻辑】标准化 ---\n",
    "# 1. 只在训练数据上 fit scaler\n",
    "scaler_wifi = StandardScaler().fit(train_data[wifi_features])\n",
    "scaler_imu = StandardScaler().fit(train_data[imu_features])\n",
    "scaler_coords = StandardScaler().fit(train_data[coord_cols])\n",
    "\n",
    "# 2. 对所有数据集进行 transform\n",
    "train_df_scaled = train_data.copy()\n",
    "val_df_scaled = val_data.copy()\n",
    "test_df_scaled = test_data.copy()\n",
    "\n",
    "for df in [train_df_scaled, val_df_scaled, test_df_scaled]:\n",
    "    df[wifi_features] = scaler_wifi.transform(df[wifi_features])\n",
    "    df[imu_features] = scaler_imu.transform(df[imu_features])\n",
    "    df[coord_cols] = scaler_coords.transform(df[coord_cols])\n",
    "\n",
    "print(\"数据已在DataFrame上完成标准化。\")\n",
    "\n",
    "# ==============================================================================\n",
    "#  第二部分：数据塑形 - 创建滑动窗口\n",
    "# ==============================================================================\n",
    "def create_sliding_windows(df, feature_cols, label_cols, window_size, future_steps):\n",
    "    X, y = [], []\n",
    "    num_samples = len(df) - window_size - future_steps + 1\n",
    "    \n",
    "    feature_data = df[feature_cols].values\n",
    "    label_data = df[label_cols].values\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        feature_window = feature_data[i : i + window_size]\n",
    "        X.append(feature_window)\n",
    "        label_window = label_data[i + window_size : i + window_size + future_steps]\n",
    "        y.append(label_window.flatten())\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "print(\"\\n--- 步骤 2: 创建滑动窗口数据 ---\")\n",
    "windows_size = 20\n",
    "future_steps = 3\n",
    "\n",
    "all_features = wifi_features + imu_features\n",
    "label_cols = ['x_coord', 'y_coord']\n",
    "\n",
    "X_train, y_train = create_sliding_windows(train_df_scaled, all_features, label_cols, windows_size, future_steps)\n",
    "X_val, y_val = create_sliding_windows(val_df_scaled, all_features, label_cols, windows_size, future_steps)\n",
    "X_test, y_test = create_sliding_windows(test_df_scaled, all_features, label_cols, windows_size, future_steps)\n",
    "\n",
    "print(\"滑动窗口数据创建完毕！\")\n",
    "print(f\"  - X_train shape: {X_train.shape}\")\n",
    "print(f\"  - y_train shape: {y_train.shape}\")\n",
    "\n",
    "# ==============================================================================\n",
    "#  第三部分：Keras TKAN 模型训练与评估\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 步骤 3: 构建与训练 Keras TKAN 模型 ---\")\n",
    "\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "output_dim = y_train.shape[1]\n",
    "\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "tkan_output = TKAN(units=32, return_sequences=False, name=\"TKAN_Layer\")(inputs)\n",
    "outputs = keras.layers.Dense(output_dim, name=\"Prediction_Head\")(tkan_output)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=keras.losses.Huber(),\n",
    "    metrics=['mse']\n",
    ")\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(\"\\n--- 开始模型训练 (model.fit) ---\")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    shuffle=False,\n",
    "    batch_size=64,\n",
    "    epochs=20,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "print(\"--- 模型训练结束 ---\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "#  第四部分：评估\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 步骤 4: 在测试集上评估最终模型 ---\")\n",
    "\n",
    "print(\"\\n--- 开始在测试集上评估 (model.evaluate) ---\")\n",
    "test_loss, test_mse = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(\"\\n--- 开始在测试集上预测 (model.predict) ---\")\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# --- 【核心修正】反标准化逻辑 ---\n",
    "y_test_seq = y_test.reshape(-1, future_steps, 2)\n",
    "y_pred_seq = y_pred.reshape(-1, future_steps, 2)\n",
    "\n",
    "# 我们关心最后一步的预测\n",
    "true_coords_scaled = y_test_seq[:, -1, :]\n",
    "pred_coords_scaled = y_pred_seq[:, -1, :]\n",
    "\n",
    "# 使用同一个 scaler_coords 进行反标准化\n",
    "true_coords = scaler_coords.inverse_transform(true_coords_scaled)\n",
    "pred_coords = scaler_coords.inverse_transform(pred_coords_scaled)\n",
    "# --- [修正结束] ---\n",
    "\n",
    "rmse = np.sqrt(np.mean((true_coords - pred_coords)**2))\n",
    "ade = np.mean(np.sqrt(np.sum((true_coords - pred_coords)**2, axis=1)))\n",
    "\n",
    "print(\"\\n--- Keras TKAN 模型评估结果 ---\")\n",
    "print(f\"Test Loss (Huber): {test_loss:.4f}\")\n",
    "print(f\"Test MSE: {test_mse:.4f} (米^2, 标准化后)\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"总均方根误差 (RMSE): {rmse:.4f} (米)\")\n",
    "print(f\"平均位移误差 (ADE/FDE): {ade:.4f} (米)\")\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "#  第五部分：保存最终预测结果\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 步骤 5: 保存预测结果到 CSV 文件 ---\")\n",
    "results_df = pd.DataFrame({\n",
    "    'True_X': true_coords[:, 0],\n",
    "    'True_Y': true_coords[:, 1],\n",
    "    'Pred_X': pred_coords[:, 0],\n",
    "    'Pred_Y': pred_coords[:, 1]\n",
    "})\n",
    "\n",
    "output_filename = 'results/tkan_UWP.csv'\n",
    "os.makedirs('results', exist_ok=True) # 确保 results 文件夹存在\n",
    "results_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"✅ 预测结果已成功保存到: {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a883b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "--- 步骤 0: 设备验证 ---\n",
      "✅ PyTorch 检测到 CUDA GPU: NVIDIA GeForce RTX 3070 Ti\n",
      "================================================================================\n",
      "\n",
      "--- 步骤 1: 加载与预处理数据 ---\n",
      "\n",
      "Identified 6 WiFi features and 9 IMU features.\n",
      "数据标准化完成。\n",
      "\n",
      "--- 步骤 2: 创建滑动窗口数据 ---\n",
      "Test data shape: (764, 30, 15)\n",
      "\n",
      "--- 步骤 3: 构建与训练 Keras TKAN 模型 ---\n",
      "\n",
      "--- 开始模型训练 ---\n",
      "Epoch 1/50\n",
      "12/12 - 4s - 370ms/step - loss: 0.4368 - mse: 0.9689 - val_loss: 0.4463 - val_mse: 0.9995\n",
      "Epoch 2/50\n",
      "12/12 - 5s - 387ms/step - loss: 0.4187 - mse: 0.9258 - val_loss: 0.4306 - val_mse: 0.9620\n",
      "Epoch 3/50\n",
      "12/12 - 5s - 390ms/step - loss: 0.4042 - mse: 0.8916 - val_loss: 0.4176 - val_mse: 0.9323\n",
      "Epoch 4/50\n",
      "12/12 - 5s - 376ms/step - loss: 0.3913 - mse: 0.8621 - val_loss: 0.4057 - val_mse: 0.9056\n",
      "Epoch 5/50\n",
      "12/12 - 5s - 380ms/step - loss: 0.3789 - mse: 0.8339 - val_loss: 0.3939 - val_mse: 0.8800\n",
      "Epoch 6/50\n",
      "12/12 - 5s - 381ms/step - loss: 0.3659 - mse: 0.8038 - val_loss: 0.3811 - val_mse: 0.8499\n",
      "Epoch 7/50\n",
      "12/12 - 5s - 383ms/step - loss: 0.3515 - mse: 0.7693 - val_loss: 0.3676 - val_mse: 0.8187\n",
      "Epoch 8/50\n",
      "12/12 - 5s - 388ms/step - loss: 0.3360 - mse: 0.7330 - val_loss: 0.3531 - val_mse: 0.7870\n",
      "Epoch 9/50\n",
      "12/12 - 5s - 386ms/step - loss: 0.3185 - mse: 0.6935 - val_loss: 0.3375 - val_mse: 0.7524\n",
      "Epoch 10/50\n",
      "12/12 - 5s - 387ms/step - loss: 0.2985 - mse: 0.6463 - val_loss: 0.3190 - val_mse: 0.7083\n",
      "Epoch 11/50\n",
      "12/12 - 5s - 381ms/step - loss: 0.2765 - mse: 0.5946 - val_loss: 0.2992 - val_mse: 0.6630\n",
      "Epoch 12/50\n",
      "12/12 - 5s - 399ms/step - loss: 0.2523 - mse: 0.5381 - val_loss: 0.2768 - val_mse: 0.6090\n",
      "Epoch 13/50\n",
      "12/12 - 5s - 398ms/step - loss: 0.2255 - mse: 0.4766 - val_loss: 0.2550 - val_mse: 0.5585\n",
      "Epoch 14/50\n",
      "12/12 - 5s - 392ms/step - loss: 0.1996 - mse: 0.4179 - val_loss: 0.2317 - val_mse: 0.5026\n",
      "Epoch 15/50\n",
      "12/12 - 5s - 404ms/step - loss: 0.1743 - mse: 0.3612 - val_loss: 0.2100 - val_mse: 0.4507\n",
      "Epoch 16/50\n",
      "12/12 - 5s - 395ms/step - loss: 0.1518 - mse: 0.3120 - val_loss: 0.1931 - val_mse: 0.4106\n",
      "Epoch 17/50\n",
      "12/12 - 5s - 395ms/step - loss: 0.1343 - mse: 0.2740 - val_loss: 0.1748 - val_mse: 0.3665\n",
      "Epoch 18/50\n",
      "12/12 - 5s - 402ms/step - loss: 0.1200 - mse: 0.2435 - val_loss: 0.1616 - val_mse: 0.3355\n",
      "Epoch 19/50\n",
      "12/12 - 5s - 392ms/step - loss: 0.1087 - mse: 0.2201 - val_loss: 0.1521 - val_mse: 0.3141\n",
      "Epoch 20/50\n",
      "12/12 - 5s - 402ms/step - loss: 0.0991 - mse: 0.2005 - val_loss: 0.1419 - val_mse: 0.2913\n",
      "Epoch 21/50\n",
      "12/12 - 5s - 403ms/step - loss: 0.0915 - mse: 0.1848 - val_loss: 0.1314 - val_mse: 0.2685\n",
      "Epoch 22/50\n",
      "12/12 - 5s - 402ms/step - loss: 0.0843 - mse: 0.1701 - val_loss: 0.1251 - val_mse: 0.2551\n",
      "Epoch 23/50\n",
      "12/12 - 5s - 399ms/step - loss: 0.0783 - mse: 0.1579 - val_loss: 0.1201 - val_mse: 0.2449\n",
      "Epoch 24/50\n",
      "12/12 - 5s - 380ms/step - loss: 0.0732 - mse: 0.1473 - val_loss: 0.1138 - val_mse: 0.2316\n",
      "Epoch 25/50\n",
      "12/12 - 5s - 387ms/step - loss: 0.0681 - mse: 0.1370 - val_loss: 0.1092 - val_mse: 0.2221\n",
      "Epoch 26/50\n",
      "12/12 - 5s - 385ms/step - loss: 0.0635 - mse: 0.1277 - val_loss: 0.1048 - val_mse: 0.2130\n",
      "Epoch 27/50\n",
      "12/12 - 5s - 407ms/step - loss: 0.0594 - mse: 0.1193 - val_loss: 0.1013 - val_mse: 0.2058\n",
      "Epoch 28/50\n",
      "12/12 - 5s - 402ms/step - loss: 0.0555 - mse: 0.1113 - val_loss: 0.0990 - val_mse: 0.2011\n",
      "Epoch 29/50\n",
      "12/12 - 5s - 393ms/step - loss: 0.0518 - mse: 0.1039 - val_loss: 0.0943 - val_mse: 0.1911\n",
      "Epoch 30/50\n",
      "12/12 - 5s - 412ms/step - loss: 0.0481 - mse: 0.0963 - val_loss: 0.0943 - val_mse: 0.1916\n",
      "Epoch 31/50\n",
      "12/12 - 5s - 413ms/step - loss: 0.0450 - mse: 0.0901 - val_loss: 0.0889 - val_mse: 0.1801\n",
      "Epoch 32/50\n",
      "12/12 - 4s - 367ms/step - loss: 0.0423 - mse: 0.0847 - val_loss: 0.0878 - val_mse: 0.1782\n",
      "Epoch 33/50\n",
      "12/12 - 4s - 368ms/step - loss: 0.0397 - mse: 0.0794 - val_loss: 0.0847 - val_mse: 0.1716\n",
      "Epoch 34/50\n",
      "12/12 - 5s - 416ms/step - loss: 0.0375 - mse: 0.0750 - val_loss: 0.0829 - val_mse: 0.1680\n",
      "Epoch 35/50\n",
      "12/12 - 6s - 493ms/step - loss: 0.0354 - mse: 0.0708 - val_loss: 0.0804 - val_mse: 0.1628\n",
      "Epoch 36/50\n",
      "12/12 - 5s - 445ms/step - loss: 0.0335 - mse: 0.0670 - val_loss: 0.0785 - val_mse: 0.1589\n",
      "Epoch 37/50\n",
      "12/12 - 5s - 421ms/step - loss: 0.0318 - mse: 0.0636 - val_loss: 0.0771 - val_mse: 0.1560\n",
      "Epoch 38/50\n",
      "12/12 - 5s - 391ms/step - loss: 0.0303 - mse: 0.0605 - val_loss: 0.0757 - val_mse: 0.1533\n",
      "Epoch 39/50\n",
      "12/12 - 5s - 393ms/step - loss: 0.0287 - mse: 0.0575 - val_loss: 0.0736 - val_mse: 0.1489\n",
      "Epoch 40/50\n",
      "12/12 - 5s - 388ms/step - loss: 0.0274 - mse: 0.0548 - val_loss: 0.0728 - val_mse: 0.1474\n",
      "Epoch 41/50\n",
      "12/12 - 5s - 378ms/step - loss: 0.0263 - mse: 0.0526 - val_loss: 0.0716 - val_mse: 0.1450\n",
      "Epoch 42/50\n",
      "12/12 - 4s - 369ms/step - loss: 0.0250 - mse: 0.0500 - val_loss: 0.0695 - val_mse: 0.1407\n",
      "Epoch 43/50\n",
      "12/12 - 4s - 362ms/step - loss: 0.0239 - mse: 0.0478 - val_loss: 0.0685 - val_mse: 0.1386\n",
      "Epoch 44/50\n",
      "12/12 - 5s - 390ms/step - loss: 0.0229 - mse: 0.0458 - val_loss: 0.0666 - val_mse: 0.1349\n",
      "Epoch 45/50\n",
      "12/12 - 5s - 385ms/step - loss: 0.0219 - mse: 0.0439 - val_loss: 0.0655 - val_mse: 0.1327\n",
      "Epoch 46/50\n",
      "12/12 - 5s - 381ms/step - loss: 0.0211 - mse: 0.0422 - val_loss: 0.0643 - val_mse: 0.1302\n",
      "Epoch 47/50\n",
      "12/12 - 4s - 365ms/step - loss: 0.0202 - mse: 0.0405 - val_loss: 0.0642 - val_mse: 0.1302\n",
      "Epoch 48/50\n",
      "12/12 - 4s - 370ms/step - loss: 0.0195 - mse: 0.0390 - val_loss: 0.0621 - val_mse: 0.1258\n",
      "Epoch 49/50\n",
      "12/12 - 4s - 369ms/step - loss: 0.0188 - mse: 0.0376 - val_loss: 0.0619 - val_mse: 0.1257\n",
      "Epoch 50/50\n",
      "12/12 - 4s - 364ms/step - loss: 0.0182 - mse: 0.0363 - val_loss: 0.0600 - val_mse: 0.1217\n",
      "\n",
      "================================================================================\n",
      "--- 步骤 4: 推理速度测试与评估 ---\n",
      "================================================================================\n",
      "正在进行模型预热...\n",
      "预热完成。\n",
      "开始在测试集上进行全量预测...\n",
      "\n",
      "==================================================\n",
      "INFERENCE SPEED REPORT (TKAN)\n",
      "--------------------------------------------------\n",
      "Device:               CUDA\n",
      "Total Samples:        764\n",
      "Total Time:           3.2646 s\n",
      "FPS (Samples/Sec):    234.03\n",
      "Avg Time per Sample:  4.2730 ms (毫秒)\n",
      "==================================================\n",
      "\n",
      "Test RMSE: 2.4415 m\n",
      "Test ADE:  2.1313 m\n",
      "\n",
      "--- 步骤 5: 保存预测结果 ---\n",
      "✅ 结果已保存至: results/tkan_zoulang.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time  # <--- 【新增】导入 time 模块\n",
    "\n",
    "# ==============================================================================\n",
    "#  环境设置与依赖检查\n",
    "# ==============================================================================\n",
    "\n",
    "# 设置 Keras 后端为 PyTorch\n",
    "os.environ['KERAS_BACKEND'] = 'torch'\n",
    "\n",
    "try:\n",
    "    import keras\n",
    "    import torch \n",
    "    from packaging.version import parse as parse_version\n",
    "    \n",
    "    if parse_version(keras.__version__) < parse_version(\"3.0.0\"):\n",
    "        print(\"错误：检测到过时的 Keras 版本。需要 Keras 3+。\")\n",
    "        exit()\n",
    "\n",
    "    from tkan import TKAN \n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"导入错误: {e}\")\n",
    "    exit()\n",
    "\n",
    "# ==============================================================================\n",
    "#  设备验证模块\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"--- 步骤 0: 设备验证 ---\")\n",
    "device_type = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device_type = \"cuda\"\n",
    "    print(f\"✅ PyTorch 检测到 CUDA GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"❌ 警告：未检测到 GPU，将在 CPU 上运行。\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ==============================================================================\n",
    "#  第一部分：数据加载与预处理\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 步骤 1: 加载与预处理数据 ---\")\n",
    "# dictory = \"../Datasets/\"\n",
    "# # 请确保文件名正确\n",
    "# filename = \"0.275_Speed_OB.csv\" \n",
    "\n",
    "# # 为了防止路径错误，增加简单的异常处理\n",
    "# try:\n",
    "#     data = pd.read_csv(dictory+filename)\n",
    "#     # data = pd.read_csv(r'../Datasets/zoulang/test.csv') # 如果需要替换测试数据\n",
    "# except FileNotFoundError:\n",
    "#     print(f\"❌ 错误：找不到文件 {dictory+filename}\")\n",
    "#     print(\"请检查路径或文件名。\")\n",
    "#     exit()\n",
    "\n",
    "# print(f\"成功加载数据集，总行数: {len(data)}\")\n",
    "\n",
    "# # 数据分割\n",
    "# train_ratio = 0.8\n",
    "# val_ratio = 0.1\n",
    "# data_size = len(data)\n",
    "# train_end_idx = int(train_ratio * data_size)\n",
    "# val_end_idx = train_end_idx + int(val_ratio * data_size)\n",
    "\n",
    "# train_data = data.iloc[:train_end_idx]\n",
    "# val_data = data.iloc[train_end_idx:val_end_idx]\n",
    "# test_data = data.iloc[val_end_idx:]\n",
    "\n",
    "train_data = pd.read_csv(\n",
    "    r'../Datasets/zoulang/train.csv')\n",
    "val_data = pd.read_csv(\n",
    "    r'../Datasets/zoulang/validation.csv')\n",
    "test_data = pd.read_csv(\n",
    "    r'../Datasets/zoulang/test.csv')\n",
    "# 特征列定义\n",
    "column_names = train_data.drop(['timestamp','x_coord', 'y_coord'], axis=1, errors='ignore').columns.tolist()\n",
    "wifi_features = [col for col in column_names if any(sensor in col for sensor in [\"rot\", \"RSSI\"])]\n",
    "imu_features = [col for col in column_names if any(sensor in col for sensor in [\"accelerometer\", \"gyroscope\",\"magnetometer\"])] \n",
    "coord_cols = ['x_coord', 'y_coord']\n",
    "\n",
    "print(f\"\\nIdentified {len(wifi_features)} WiFi features and {len(imu_features)} IMU features.\")\n",
    "\n",
    "# 标准化\n",
    "scaler_wifi = StandardScaler().fit(train_data[wifi_features])\n",
    "scaler_imu = StandardScaler().fit(train_data[imu_features])\n",
    "# 【关键】单独定义 label 的 scaler，方便后续反标准化\n",
    "scaler_label = StandardScaler().fit(train_data[coord_cols]) \n",
    "\n",
    "train_df_scaled = train_data.copy()\n",
    "val_df_scaled = val_data.copy()\n",
    "test_df_scaled = test_data.copy()\n",
    "\n",
    "for df in [train_df_scaled, val_df_scaled, test_df_scaled]:\n",
    "    df[wifi_features] = scaler_wifi.transform(df[wifi_features])\n",
    "    df[imu_features] = scaler_imu.transform(df[imu_features])\n",
    "    df[coord_cols] = scaler_label.transform(df[coord_cols])\n",
    "\n",
    "print(\"数据标准化完成。\")\n",
    "\n",
    "# ==============================================================================\n",
    "#  第二部分：数据塑形 - 创建滑动窗口\n",
    "# ==============================================================================\n",
    "def create_sliding_windows(df, feature_cols, label_cols, window_size, future_steps):\n",
    "    X, y = [], []\n",
    "    num_samples = len(df) - window_size - future_steps + 1\n",
    "    \n",
    "    feature_data = df[feature_cols].values\n",
    "    label_data = df[label_cols].values\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        feature_window = feature_data[i : i + window_size]\n",
    "        X.append(feature_window)\n",
    "        # 展平 y 以适配 Dense 层输出\n",
    "        label_window = label_data[i + window_size : i + window_size + future_steps]\n",
    "        y.append(label_window.flatten())\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "print(\"\\n--- 步骤 2: 创建滑动窗口数据 ---\")\n",
    "windows_size = 30\n",
    "future_steps = 3\n",
    "\n",
    "all_features = wifi_features + imu_features\n",
    "X_train, y_train = create_sliding_windows(train_df_scaled, all_features, coord_cols, windows_size, future_steps)\n",
    "X_val, y_val = create_sliding_windows(val_df_scaled, all_features, coord_cols, windows_size, future_steps)\n",
    "X_test, y_test = create_sliding_windows(test_df_scaled, all_features, coord_cols, windows_size, future_steps)\n",
    "\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "\n",
    "# ==============================================================================\n",
    "#  第三部分：Keras TKAN 模型训练\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 步骤 3: 构建与训练 Keras TKAN 模型 ---\")\n",
    "\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "output_dim = y_train.shape[1]\n",
    "\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "# TKAN 层\n",
    "tkan_output = TKAN(units=32, return_sequences=False, name=\"TKAN_Layer\")(inputs)\n",
    "outputs = keras.layers.Dense(output_dim, name=\"Prediction_Head\")(tkan_output)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
    "    loss=keras.losses.Huber(),\n",
    "    metrics=['mse']\n",
    ")\n",
    "\n",
    "# 减少 epochs 以便测试代码，实际使用可改回 50\n",
    "print(\"\\n--- 开始模型训练 ---\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=64,\n",
    "    epochs=50, # 如果只是测试代码，可以改小，比如 5\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# ==============================================================================\n",
    "#  第四部分：评估与计时 (包含毫秒级统计)\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"--- 步骤 4: 推理速度测试与评估 ---\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. 预热 (Warm-up)\n",
    "# Keras/PyTorch 第一次运行由于图构建或内存分配，速度通常较慢。\n",
    "print(\"正在进行模型预热...\")\n",
    "if len(X_test) > 0:\n",
    "    # 取一小部分数据进行一次空跑\n",
    "    _ = model.predict(X_test[:32], verbose=0)\n",
    "print(\"预热完成。\")\n",
    "\n",
    "# 2. 正式计时\n",
    "print(\"开始在测试集上进行全量预测...\")\n",
    "\n",
    "# 如果是 CUDA 环境，必须同步\n",
    "if device_type == \"cuda\":\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "start_time = time.time() # ⏱️ 计时开始\n",
    "\n",
    "# 执行预测 (verbose=0 防止打印进度条影响计时)\n",
    "y_pred = model.predict(X_test, verbose=0)\n",
    "\n",
    "if device_type == \"cuda\":\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "end_time = time.time()   # ⏱️ 计时结束\n",
    "\n",
    "# 3. 计算时间指标\n",
    "total_time_sec = end_time - start_time\n",
    "total_samples = len(X_test)\n",
    "avg_time_ms = (total_time_sec / total_samples) * 1000 # 转换为毫秒\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"INFERENCE SPEED REPORT (TKAN)\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Device:               {device_type.upper()}\")\n",
    "print(f\"Total Samples:        {total_samples}\")\n",
    "print(f\"Total Time:           {total_time_sec:.4f} s\")\n",
    "print(f\"FPS (Samples/Sec):    {total_samples/total_time_sec:.2f}\")\n",
    "print(f\"Avg Time per Sample:  {avg_time_ms:.4f} ms (毫秒)\") # <--- 您需要的单位\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# 4. 计算误差指标\n",
    "y_test_seq = y_test.reshape(-1, future_steps, 2)\n",
    "y_pred_seq = y_pred.reshape(-1, future_steps, 2)\n",
    "\n",
    "# 取最后一步进行评估\n",
    "true_coords_scaled = y_test_seq[:, -1, :]\n",
    "pred_coords_scaled = y_pred_seq[:, -1, :]\n",
    "\n",
    "# 反标准化 (使用之前定义的 scaler_label)\n",
    "# 注意：scaler_label 是针对 [x, y] 两列 fit 的\n",
    "true_coords = scaler_label.inverse_transform(true_coords_scaled)\n",
    "pred_coords = scaler_label.inverse_transform(pred_coords_scaled)\n",
    "\n",
    "rmse = np.sqrt(np.mean(np.sum((true_coords - pred_coords)**2, axis=1))) # 修正RMSE计算方式 (先平方和再平均再开方)\n",
    "# 或者: rmse = np.sqrt(np.mean((true_coords - pred_coords)**2)) 如果是想算 element-wise 的 RMSE\n",
    "\n",
    "# ADE (Average Displacement Error) - 欧氏距离的平均值\n",
    "displacement = np.sqrt(np.sum((true_coords - pred_coords)**2, axis=1))\n",
    "ade = np.mean(displacement)\n",
    "\n",
    "print(f\"Test RMSE: {rmse:.4f} m\")\n",
    "print(f\"Test ADE:  {ade:.4f} m\")\n",
    "\n",
    "# ==============================================================================\n",
    "#  第五部分：保存结果\n",
    "# ==============================================================================\n",
    "print(\"\\n--- 步骤 5: 保存预测结果 ---\")\n",
    "results_df = pd.DataFrame({\n",
    "    'True_X': true_coords[:, 0],\n",
    "    'True_Y': true_coords[:, 1],\n",
    "    'Pred_X': pred_coords[:, 0],\n",
    "    'Pred_Y': pred_coords[:, 1]\n",
    "})\n",
    "\n",
    "output_filename = 'results/tkan_zoulang.csv'\n",
    "os.makedirs('results', exist_ok=True)\n",
    "# results_df.to_csv(output_filename, index=False)\n",
    "print(f\"✅ 结果已保存至: {output_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
